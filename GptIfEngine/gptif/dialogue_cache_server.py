import base64
import contextvars
import os
import uuid
from typing import Annotated, Any, Dict, List, Optional, Tuple, Union, cast

from dotenv import load_dotenv

from gptif.console import ConsoleHandler
from gptif.state import World

load_dotenv()  # take environment variables from .env.

from fastapi import Cookie, FastAPI, HTTPException
from fastapi.responses import Response
from fastapi.security import OAuth2PasswordBearer
from pydantic import BaseModel

import gptif.handle_input
from gptif.db import (
    AiImage,
    GptDialogue,
    create_db_and_tables,
    get_ai_image_from_id,
    get_ai_image_if_cached,
    get_answer_if_cached,
    put_ai_image_in_cache,
    put_answer_in_cache,
)
from gptif.llm import LlamaCppLanguageModel, OpenAiLanguageModel

stage = os.environ.get("STAGE", None)
root_path = f"/{stage}" if stage else "/"

app = FastAPI(title="MyAwesomeApp", root_path=root_path)
request_id_contextvar = contextvars.ContextVar("request_id", default="")

openai_model = OpenAiLanguageModel()

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")


class BufferedConsoleHandler(ConsoleHandler):
    def __init__(self):
        self.buffers: Dict[str, List[Tuple[str, Optional[str]]]] = {}

    def print(self, *objects: Any, style: Optional[str] = None):
        request_id = request_id_contextvar.get()
        assert len(request_id) > 0
        if request_id not in self.buffers:
            self.buffers[request_id] = []
        self.buffers[request_id].append(
            (BufferedConsoleHandler.merge_parameters(objects), style)
        )

    @staticmethod
    def merge_parameters(*objects: Any) -> str:
        return ", ".join([str(o) for o in objects])

    def get_input(self, prompt: str) -> str:
        raise NotImplementedError()

    def input(self, prompt: str):
        raise NotImplementedError()

    def debug(self, *objects: Any):
        pass

    def warning(self, *objects: Any):
        self.print(*objects, style="red on black")


import gptif.console

gptif.console.console = (
    BufferedConsoleHandler()
)  # Monkey patch our custom console handler


class GameCommand(BaseModel):
    command: str


@app.on_event("startup")
def on_startup():
    create_db_and_tables()


@app.middleware("http")
async def request_middleware(request, call_next):
    request_id = str(uuid.uuid4())
    request_id_contextvar.set(request_id)
    return await call_next(request)


@app.post("/fetch_dialogue")
async def fetch_dialogue(query: GptDialogue) -> str:
    answer = get_answer_if_cached(query)
    if answer is None and query.model_version == openai_model.model_name():
        # Grab the answer from openai
        assert query.stop_words is not None
        answer = openai_model.llm(
            query.context, stop=query.stop_words.split(","), echo=False
        )
        query.answer = answer
        put_answer_in_cache(query)
        return answer

    return "None" if answer is None else answer


@app.post("/fetch_image_id_for_caption")
async def fetch_image_id_for_caption(query: AiImage) -> str:
    ai_image = get_ai_image_if_cached(query)
    if ai_image is None:
        # Grab the ai_image from openai
        import openai

        response = openai.Image.create(
            prompt=query.prompt,
            n=1,
            size="256x256",
            response_format="b64_json",
        )

        image_data_b64 = response["data"][0]["b64_json"]
        image_data_bytes = base64.b64decode(image_data_b64)
        query.result = image_data_bytes

        put_ai_image_in_cache(query)

        assert query.id is not None

        return str(query.id)
    return str(ai_image.id)


@app.get(
    "/ai_image/{image_id}",
    responses={200: {"content": {"image/png": {}}}},
    # Prevent FastAPI from adding "application/json" as an additional
    # response media type in the autogenerated OpenAPI specification.
    # https://github.com/tiangolo/fastapi/issues/3258
    response_class=Response,
)
async def ai_image(image_id: str) -> Response:
    int_id = int(image_id)
    ai_image = get_ai_image_from_id(int_id)
    if ai_image is None:
        raise Exception("Oops")
    return Response(content=ai_image.result, media_type="image/png")


@app.post("/put_dialogue")
async def put_dialogue(query: GptDialogue):
    put_answer_in_cache(query)


@app.get("/")
async def root():
    return {"message": "Hello World!"}


@app.post("/handle_input")
async def handle_input(
    command: GameCommand, game_state: Annotated[Union[str, None], Cookie()] = None
) -> Response:
    world = World()
    if game_state is not None:
        if not world.load(game_state):
            raise HTTPException(status_code=400, detail="Incompatible world version")
    gptif.handle_input.handle_input(world, command.command)
    request_id = request_id_contextvar.get()
    response = Response(
        content=cast(BufferedConsoleHandler, gptif.console.console).buffers.get(
            request_id, []
        )
    )
    response.set_cookie(key="game_state", value=world.save())
    return response
