import os
import base64

from dotenv import load_dotenv

load_dotenv()  # take environment variables from .env.

from fastapi import FastAPI
from fastapi.responses import Response
from pydantic import BaseModel

from gptif.db import (
    GptDialogue,
    AiImage,
    create_db_and_tables,
    get_answer_if_cached,
    put_answer_in_cache,
    get_ai_image_if_cached,
    put_ai_image_in_cache,
    get_ai_image_from_id,
)
from gptif.llm import LlamaCppLanguageModel, OpenAiLanguageModel

stage = os.environ.get("STAGE", None)
root_path = f"/{stage}" if stage else "/"

app = FastAPI(title="MyAwesomeApp", root_path=root_path)

openai_model = OpenAiLanguageModel()


@app.on_event("startup")
def on_startup():
    create_db_and_tables()


@app.post("/fetch_dialogue")
async def fetch_dialogue(query: GptDialogue) -> str:
    answer = get_answer_if_cached(query)
    if answer is None and query.model_version == openai_model.model_name():
        # Grab the answer from openai
        assert query.stop_words is not None
        answer = openai_model.llm(
            query.context, stop=query.stop_words.split(","), echo=False
        )
        query.answer = answer
        put_answer_in_cache(query)
        return answer

    return "None" if answer is None else answer


@app.post("/fetch_image_id_for_caption")
async def fetch_image_id_for_caption(query: AiImage) -> str:
    ai_image = get_ai_image_if_cached(query)
    if ai_image is None:
        # Grab the ai_image from openai
        import openai

        response = openai.Image.create(
            prompt=query.prompt,
            n=1,
            size="256x256",
            response_format="b64_json",
        )

        image_data_b64 = response["data"][0]["b64_json"]
        image_data_bytes = base64.b64decode(image_data_b64)
        query.result = image_data_bytes

        put_ai_image_in_cache(query)

        assert query.id is not None

        return str(query.id)
    return str(ai_image.id)


@app.get(
    "/ai_image/{image_id}",
    responses={200: {"content": {"image/png": {}}}},
    # Prevent FastAPI from adding "application/json" as an additional
    # response media type in the autogenerated OpenAPI specification.
    # https://github.com/tiangolo/fastapi/issues/3258
    response_class=Response,
)
async def ai_image(image_id: str) -> Response:
    int_id = int(image_id)
    ai_image = get_ai_image_from_id(int_id)
    if ai_image is None:
        raise Exception("Oops")
    return Response(content=ai_image.result, media_type="image/png")


@app.post("/put_dialogue")
async def put_dialogue(query: GptDialogue):
    put_answer_in_cache(query)


@app.get("/")
async def root():
    return {"message": "Hello World!"}
